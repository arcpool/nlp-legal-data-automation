{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "import json\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I/P :Read json files\n",
    "## O/P : Returns a  json  file as dictionary\n",
    "\n",
    "def read_json(a_case):\n",
    "    f = open(a_case)       \n",
    "    case = json.load(f) \n",
    "    return case  \n",
    "read_json_transformer = FunctionTransformer(read_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I/P :dictionary from each json file\n",
    "## O/P : Return paragraphs from each json file\n",
    "\n",
    "def extract_para(case):\n",
    "    all_para= case['paragraphs']\n",
    "    paras= []\n",
    "    para_id =0\n",
    "    for a_para in all_para:\n",
    "        para_id = para_id+1\n",
    "        #### Main Para\n",
    "        main_para_id = \"p_\" + str(para_id)\n",
    "        main_para = a_para[\"para\"][0]          \n",
    "        paras.append([para_id, main_para_id,main_para]) \n",
    "        \n",
    "        ####  For BlockQuotes\n",
    "        block_quote =  a_para[\"blockQuotes\"]    \n",
    "        \n",
    "        if len(block_quote) != 0:            \n",
    "            bq = (block_quote[0].split(\"\\n\")) \n",
    "            bq_count = 0\n",
    "            for a_bq in bq:\n",
    "                bq_count = bq_count +1   \n",
    "                paras.append([para_id, \"bq_\"+ str(bq_count),a_bq])\n",
    "                \n",
    "        #### for Subpara\n",
    "        sub_para = a_para[\"subPara\"]      \n",
    "        if len(sub_para) != 0:\n",
    "            sub_para = list(sub_para.values())\n",
    "            sub_para_id = 0 \n",
    "            for a_pre in sub_para:\n",
    "                sub_para_id =sub_para_id+1\n",
    "                \n",
    "                paras.append([para_id, \"subpara_\"+ str(sub_para_id),a_pre])\n",
    "                    \n",
    "    para_df = pd.DataFrame(paras, columns=[\"ParaID\",\"ContentID\",\"Paragraph\"])\n",
    "        \n",
    "    return para_df\n",
    "\n",
    "extract_para_transformer = FunctionTransformer(extract_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following pipeline will call both the above function together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = Pipeline([\n",
    "    (\"read_json\", read_json_transformer),\n",
    "    (\"extract_para\",extract_para_transformer),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph Extracted\n"
     ]
    }
   ],
   "source": [
    "parent_path = Path(r'C:\\Users\\Nabanita Paul\\output\\2017\\New folder') ## Change the path here . Give the path where json file for each case is available\n",
    "for a_file in parent_path.rglob('*.json'):    \n",
    "    para = data_pipeline.fit_transform(a_file)\n",
    "    path , file_name = os.path.split(a_file)    \n",
    "    file_name = file_name.replace(\".json\",\".csv\")\n",
    "    a_file = os.path.join(path,file_name,)\n",
    "    para.to_csv(a_file,index=False)\n",
    "print(\"Paragraph Extracted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csv file will be generated for each of the json file given as input "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
